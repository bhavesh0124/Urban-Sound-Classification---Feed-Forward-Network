{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Urban Sound Classificaion | training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "456ivtIl7SBp",
        "outputId": "900e6508-e122-4b04-f818-1ca85b2c1b25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW6QSnSNepiK"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "import librosa\n",
        "import os\n",
        "import seaborn as sns\n",
        "from matplotlib.pyplot import specgram\n",
        "from sklearn.model_selection import KFold\n",
        "import librosa.display\n",
        "import IPython as ipd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "%matplotlib inline\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN-thNTZCEtK"
      },
      "source": [
        "csv_path=\"/content/drive/MyDrive/Datasets-Collab/Urban Sound Classification\"\n",
        "audio_path=\"/content/drive/MyDrive/train.zip (Unzipped Files)/Train/\"\n",
        "processed_path=\"/content/drive/MyDrive/Datasets-Collab/Urban Sound Classification/processed/\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_KZ4AA7e4FL"
      },
      "source": [
        "df_train=pd.read_csv(csv_path+'/Train.csv')\n",
        "df_test=pd.read_csv(csv_path+'/Test.csv')\n",
        "submission=pd.read_csv(csv_path+'/sample_submission.csv')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSzMOjeintYl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Label_encoder=LabelEncoder()\n",
        "\n",
        "df_train['Class']=Label_encoder.fit_transform(df_train['Class'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbefB_aolDSY"
      },
      "source": [
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "    return mfccs,chroma,mel,contrast,tonnetz\n",
        "\n",
        "def parse_audio_files(file_name,label):\n",
        "    fn=file_name\n",
        "    features, labels = np.empty((0,193)), np.empty(0) # 193 => total features \n",
        "    mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
        "    ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
        "    features = np.vstack([features,ext_features])\n",
        "    labels = np.append(labels,label)\n",
        "    return np.array(features, dtype=np.float32), np.array(labels, dtype = np.int8)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg_4XA1L6QPm"
      },
      "source": [
        "# temp=df_train.head(10)\n",
        "# sound_path=[]\n",
        "# for i,label in zip(temp['ID'],temp['Class']):\n",
        "#   sound_path=audio_path+str(i)+'.wav'\n",
        "#   features, labels = parse_audio_files(sound_path,label)\n",
        "#   np.savez(processed_path+str(i), features=features, \n",
        "#              labels=labels)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmr3IICimYSn"
      },
      "source": [
        "# temp=df_train\n",
        "# sound_path=[]\n",
        "# for i,label in zip(temp['ID'],temp['Class']):\n",
        "#   sound_path=audio_path+str(i)+'.wav'\n",
        "#   features, labels = parse_audio_files(sound_path,label)\n",
        "#   np.savez(processed_path+str(i), features=features, \n",
        "#              labels=labels)\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JxMD3Dfm6Gv"
      },
      "source": [
        "split=int(0.7*df_train.shape[0])\n",
        "x_train, y_train = [], []\n",
        "x_test, y_test= [] , []\n",
        "i=0\n",
        "for files in df_train['ID']:\n",
        "  files=str(files)+'.npz'\n",
        "  data=np.load(processed_path+files)\n",
        "  if (i<split):\n",
        "    x_train.append(data[\"features\"])\n",
        "    y_train.append(data[\"labels\"])\n",
        "  else:\n",
        "    x_test.append(data[\"features\"])\n",
        "    y_test.append(data[\"labels\"])\n",
        "  i=i+1\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8U9ujXi9ahn"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u4y8bOOa_gn"
      },
      "source": [
        "x_train=np.concatenate(x_train, axis = 0)\n",
        "y_train = np.concatenate(y_train, axis = 0)\n",
        "x_test=np.concatenate(x_test, axis = 0)\n",
        "y_test = np.concatenate(y_test, axis = 0)\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZgHX9xSZaqD"
      },
      "source": [
        "def get_network():\n",
        "    input_shape = (193,)\n",
        "    num_classes = 10\n",
        "    keras.backend.clear_session()\n",
        "    \n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(256, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(keras.layers.Dense(64, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(keras.layers.Dense(num_classes, activation = \"softmax\"))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(), \n",
        "        metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2CCRyUyaDvT",
        "outputId": "fa5dccac-e0cb-427a-cad4-3deff52fe94a"
      },
      "source": [
        "accuracies = []\n",
        "model = get_network()\n",
        "model.fit(x_train, y_train, epochs = 100, batch_size = 24, validation_data=(x_test,y_test) ,verbose = 0)\n",
        "l, a = model.evaluate(x_test, y_test, verbose = 0)\n",
        "accuracies.append(a)\n",
        "print(\"Loss: {0} | Accuracy: {1}\".format(l, a))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.7615966200828552 | Accuracy: 0.9031268954277039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmoc0xrhmzJ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}